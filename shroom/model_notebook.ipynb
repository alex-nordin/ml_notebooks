{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: For the teachers (or are you called examiners?), as of now all work within this notebook is done by Alex Nordin\n",
    "#\n",
    "# Code Ownership Tag -> @Alex Nordin\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-12 13:12:04.167926: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-12 13:12:04.485603: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-12-12 13:12:05.303772: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-12 13:12:05.303859: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-12 13:12:05.303866: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.applications import vgg16, inception_v3\n",
    "from keras.optimizers import schedules\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.models import load_model\n",
    "from keras import utils\n",
    "#install using pip3 install vit-keras.\n",
    "from vit_keras import vit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Path to the directories containing our data sets. Change to wherever they are on your machine to use the notebook.Kaggle URL: https://www.kaggle.com/datasets/mustai/mushroom-12-9528\n",
    "mush_alt_train = '/home/alex/Documents/AI_proj/mush_alt/train'\n",
    "mush_alt_val = '/home/alex/Documents/AI_proj/mush_alt/valid'\n",
    "mush_alt_test = '/home/alex/Documents/AI_proj/mush_alt/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6664 files belonging to 12 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-12 13:13:05.513178: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-12 13:13:05.608916: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-12 13:13:05.609674: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-12 13:13:05.613388: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-12 13:13:05.614979: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-12 13:13:05.615555: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-12 13:13:05.616008: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-12 13:13:06.326679: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-12 13:13:06.327125: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-12 13:13:06.327263: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-12 13:13:06.327427: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6292 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2070 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 953 files belonging to 12 classes.\n",
      "Found 1911 files belonging to 12 classes.\n"
     ]
    }
   ],
   "source": [
    "#img_size = 180\n",
    "#Had to change image size to be bigger to work with vit model. Slows down performance and requires more memory. :/\n",
    "img_size = 224\n",
    "\n",
    "#The uploader of the dataset very nicely divided it into training/validation/testing sets for us, so we just import each folder in turn.\n",
    "#image_dataset_from_directory() assigns the labels for the images as the subdirectories inside the folders. very convenient\n",
    "training_set = tf.keras.utils.image_dataset_from_directory(\n",
    "    mush_alt_train,\n",
    "    seed=123,\n",
    "    image_size=(img_size, img_size)\n",
    ")\n",
    "\n",
    "validation_set = tf.keras.utils.image_dataset_from_directory(\n",
    "    mush_alt_val,\n",
    "    seed=123,\n",
    "    image_size=(img_size, img_size)\n",
    ")\n",
    "\n",
    "test_set = tf.keras.utils.image_dataset_from_directory(\n",
    "    mush_alt_test,\n",
    "    seed=123,\n",
    "    image_size=(img_size, img_size)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get better performance over such a large data set we cache(), keeping the dataset in memory after the first epoch\n",
    "# Additionally prefetch() allows us to \"overlap preprocessing and model execution during training\"\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "training_set = training_set.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "validation_set = validation_set.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "test_set = validation_set.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/.local/lib/python3.10/site-packages/vit_keras/utils.py:81: UserWarning: Resizing position embeddings from 12, 12 to 7, 7\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#vg16 is a pre-trained model with purported high performance an accuracy\n",
    "# base_model = vgg16.VGG16(weights=\"imagenet\", \n",
    "#     include_top=False,\n",
    "#     input_shape=(img_height, img_width, 3))\n",
    "\n",
    "# Inception_v3 is apparently also a good pre-trained mode. \n",
    "# base_model = inception_v3.InceptionV3(\n",
    "#     include_top=False,\n",
    "#     weights=\"imagenet\",\n",
    "#     input_shape=(img_size, img_size, 3)\n",
    "# )\n",
    "\n",
    "# #Trying our resnet50\n",
    "# base_model = ResNet50(\n",
    "#     include_top=False,\n",
    "#     weights=\"imagenet\",\n",
    "#     input_shape=(img_size, img_size, 3)\n",
    "# )\n",
    "\n",
    "#base_model.trainable = False\n",
    "\n",
    "#vit is a type of RNN called a transformer. it is our current best performer at ~80% accuracy on our validation and testing sets\n",
    "base_model = vit.vit_b32(\n",
    "    image_size=(img_size),\n",
    "    activation=\"softmax\",\n",
    "    pretrained=True,\n",
    "    include_top=False,\n",
    "    pretrained_top=False,\n",
    "    classes=12\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A few different schedulers to decay our learning rate as training progresses. Currently not in use in favor of a callback method that decreases lr when it plateus.\n",
    "\n",
    "# scheduler = keras.optimizers.schedules.CosineDecay(\n",
    "#     initial_learning_rate=0.001,\n",
    "#     decay_steps=10000,\n",
    "#     )\n",
    "\n",
    "# exp_scheduler = keras.optimizers.schedules.ExponentialDecay(\n",
    "#     initial_learning_rate=0.0001,\n",
    "#     decay_steps=1000,\n",
    "#     decay_rate=0.9\n",
    "#     )\n",
    "\n",
    "# fine_scheduler = keras.optimizers.schedules.CosineDecay(\n",
    "#     initial_learning_rate=0.000001,\n",
    "#     decay_steps=1000,\n",
    "#     )\n",
    "\n",
    "#learning rate constants\n",
    "lr = 1e-4\n",
    "#fine_lr = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates a sequential model which performs data augmentation. the things I've found increases accuracy are randomflip and randomrotation.\n",
    "data_aug = Sequential([\n",
    "    keras.layers.RandomFlip(mode=\"horizontal_and_vertical\", seed=987),\n",
    "    #keras.layers.RandomZoom(height_factor=(-0.2, -0.3), seed=987),\n",
    "    keras.layers.RandomRotation(factor=0.3, seed=987),\n",
    "    #keras.layers.RandomCrop(height=120, width=120, seed=987)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have twelve classes\n",
    "classes = 12\n",
    "\n",
    "\n",
    "#The model consists of the data augmentation model, a layer which rescales RBG values (0-255 in 3 layers) into values between 0 and 1 in three layers\n",
    "#base model is out pre-trained vit model, then we flatten the output of that, and feed it into a dense layer with 512 neurons, then into our output layer with 12 probabilities\n",
    "model = Sequential([\n",
    "    data_aug,\n",
    "    keras.layers.Rescaling(1./255),\n",
    "    #======\n",
    "    base_model,\n",
    "    #=====\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(512, activation='relu'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(classes, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile our model with the optimizer and loss function we want to use\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=lr), loss=tf.keras.losses.SparseCategoricalCrossentropy(), metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://app.neptune.ai/alnor/DIT825/e/DIT-89\n",
      "Remember to stop your run once you’ve finished logging your metadata (https://docs.neptune.ai/api/run#stop). It will be stopped automatically only when the notebook kernel/interactive console is terminated.\n"
     ]
    }
   ],
   "source": [
    "import neptune.new as neptune\n",
    "\n",
    "#Initiates a neptune \"run\", which shows up on my neptune page. comment out all the neptune code if you want to run the notebook, or add your own API token as an arg in this function call\n",
    "#or add your API token as a global variable (for linux you can add it as an export in .bashrc).\n",
    "run = neptune.init_run(\n",
    "    project=\"alnor/DIT825\",\n",
    "    source_files=[\"model_notebook.ipynb\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neptune.new.integrations.tensorflow_keras import NeptuneCallback\n",
    "\n",
    "#Callback that successively uploads information to neptune\n",
    "neptune_callback = NeptuneCallback(run=run, base_namespace=\"metrics\")\n",
    "#Calback that keep tracks of the metric val_loss (validation loss), and reduces the learning rate if val_loss plateus. currently used instead of scheduler\n",
    "reduce_learning_rate = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.1, patience=5, min_delta=0.0000000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 16:32:37.003662: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8600\n",
      "2022-12-06 16:32:37.853433: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209/209 [==============================] - 73s 247ms/step - loss: 1.5675 - accuracy: 0.5068 - val_loss: 1.1263 - val_accuracy: 0.6464 - lr: 1.0000e-04\n",
      "Epoch 2/30\n",
      "209/209 [==============================] - 49s 235ms/step - loss: 0.8825 - accuracy: 0.7114 - val_loss: 0.9440 - val_accuracy: 0.7072 - lr: 1.0000e-04\n",
      "Epoch 3/30\n",
      "209/209 [==============================] - 49s 236ms/step - loss: 0.6091 - accuracy: 0.7914 - val_loss: 0.7967 - val_accuracy: 0.7471 - lr: 1.0000e-04\n",
      "Epoch 4/30\n",
      "209/209 [==============================] - 49s 236ms/step - loss: 0.4474 - accuracy: 0.8487 - val_loss: 0.8751 - val_accuracy: 0.7450 - lr: 1.0000e-04\n",
      "Epoch 5/30\n",
      "209/209 [==============================] - 49s 236ms/step - loss: 0.3152 - accuracy: 0.8950 - val_loss: 0.7367 - val_accuracy: 0.7838 - lr: 1.0000e-04\n",
      "Epoch 6/30\n",
      "209/209 [==============================] - 49s 236ms/step - loss: 0.2476 - accuracy: 0.9172 - val_loss: 0.7213 - val_accuracy: 0.7954 - lr: 1.0000e-04\n",
      "Epoch 7/30\n",
      "209/209 [==============================] - 49s 236ms/step - loss: 0.1867 - accuracy: 0.9385 - val_loss: 0.7300 - val_accuracy: 0.8048 - lr: 1.0000e-04\n",
      "Epoch 8/30\n",
      "209/209 [==============================] - 49s 236ms/step - loss: 0.1433 - accuracy: 0.9524 - val_loss: 0.7586 - val_accuracy: 0.7880 - lr: 1.0000e-04\n",
      "Epoch 9/30\n",
      "209/209 [==============================] - 49s 236ms/step - loss: 0.1413 - accuracy: 0.9520 - val_loss: 0.7169 - val_accuracy: 0.8038 - lr: 1.0000e-04\n",
      "Epoch 10/30\n",
      "209/209 [==============================] - 49s 236ms/step - loss: 0.0961 - accuracy: 0.9719 - val_loss: 0.9089 - val_accuracy: 0.7744 - lr: 1.0000e-04\n",
      "Epoch 11/30\n",
      "209/209 [==============================] - 49s 236ms/step - loss: 0.0994 - accuracy: 0.9649 - val_loss: 0.7551 - val_accuracy: 0.8080 - lr: 1.0000e-04\n",
      "Epoch 12/30\n",
      "209/209 [==============================] - 49s 236ms/step - loss: 0.0989 - accuracy: 0.9677 - val_loss: 0.8430 - val_accuracy: 0.7922 - lr: 1.0000e-04\n",
      "Epoch 13/30\n",
      "209/209 [==============================] - 49s 236ms/step - loss: 0.0813 - accuracy: 0.9749 - val_loss: 0.8573 - val_accuracy: 0.8048 - lr: 1.0000e-04\n",
      "Epoch 14/30\n",
      "209/209 [==============================] - 49s 236ms/step - loss: 0.0800 - accuracy: 0.9755 - val_loss: 0.8874 - val_accuracy: 0.7954 - lr: 1.0000e-04\n",
      "Epoch 15/30\n",
      "209/209 [==============================] - 49s 236ms/step - loss: 0.0366 - accuracy: 0.9907 - val_loss: 0.7156 - val_accuracy: 0.8353 - lr: 1.0000e-05\n",
      "Epoch 16/30\n",
      "209/209 [==============================] - 49s 236ms/step - loss: 0.0251 - accuracy: 0.9938 - val_loss: 0.7003 - val_accuracy: 0.8342 - lr: 1.0000e-05\n",
      "Epoch 17/30\n",
      "209/209 [==============================] - 49s 236ms/step - loss: 0.0216 - accuracy: 0.9955 - val_loss: 0.7018 - val_accuracy: 0.8416 - lr: 1.0000e-05\n",
      "Epoch 18/30\n",
      "209/209 [==============================] - 49s 237ms/step - loss: 0.0195 - accuracy: 0.9964 - val_loss: 0.7043 - val_accuracy: 0.8342 - lr: 1.0000e-05\n",
      "Epoch 19/30\n",
      "209/209 [==============================] - 49s 236ms/step - loss: 0.0150 - accuracy: 0.9973 - val_loss: 0.6922 - val_accuracy: 0.8405 - lr: 1.0000e-05\n",
      "Epoch 20/30\n",
      "209/209 [==============================] - 49s 236ms/step - loss: 0.0148 - accuracy: 0.9976 - val_loss: 0.7076 - val_accuracy: 0.8405 - lr: 1.0000e-05\n",
      "Epoch 21/30\n",
      "209/209 [==============================] - 49s 236ms/step - loss: 0.0115 - accuracy: 0.9980 - val_loss: 0.6854 - val_accuracy: 0.8447 - lr: 1.0000e-05\n",
      "Epoch 22/30\n",
      "209/209 [==============================] - 49s 236ms/step - loss: 0.0086 - accuracy: 0.9991 - val_loss: 0.7018 - val_accuracy: 0.8395 - lr: 1.0000e-05\n",
      "Epoch 23/30\n",
      "209/209 [==============================] - 49s 236ms/step - loss: 0.0099 - accuracy: 0.9976 - val_loss: 0.7220 - val_accuracy: 0.8363 - lr: 1.0000e-05\n",
      "Epoch 24/30\n",
      "209/209 [==============================] - 49s 236ms/step - loss: 0.0084 - accuracy: 0.9986 - val_loss: 0.7098 - val_accuracy: 0.8395 - lr: 1.0000e-05\n",
      "Epoch 25/30\n",
      "209/209 [==============================] - 49s 237ms/step - loss: 0.0078 - accuracy: 0.9991 - val_loss: 0.6937 - val_accuracy: 0.8374 - lr: 1.0000e-05\n",
      "Epoch 26/30\n",
      "209/209 [==============================] - 49s 236ms/step - loss: 0.0074 - accuracy: 0.9985 - val_loss: 0.7111 - val_accuracy: 0.8405 - lr: 1.0000e-05\n",
      "Epoch 27/30\n",
      "209/209 [==============================] - 49s 237ms/step - loss: 0.0066 - accuracy: 0.9994 - val_loss: 0.7052 - val_accuracy: 0.8447 - lr: 1.0000e-06\n",
      "Epoch 28/30\n",
      "209/209 [==============================] - 49s 236ms/step - loss: 0.0069 - accuracy: 0.9989 - val_loss: 0.7111 - val_accuracy: 0.8426 - lr: 1.0000e-06\n",
      "Epoch 29/30\n",
      "209/209 [==============================] - 49s 236ms/step - loss: 0.0063 - accuracy: 0.9997 - val_loss: 0.7078 - val_accuracy: 0.8395 - lr: 1.0000e-06\n",
      "Epoch 30/30\n",
      "209/209 [==============================] - 49s 236ms/step - loss: 0.0059 - accuracy: 0.9989 - val_loss: 0.7085 - val_accuracy: 0.8426 - lr: 1.0000e-06\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7febb43b3c10>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model, for 20 epochs, cross validating with our validation set. Do not run if you can't run on your GPU or it will take forever. Even running on GPU expect it to take up to 10 min\n",
    "model.fit(training_set, validation_data=validation_set, epochs=30, callbacks=[neptune_callback, reduce_learning_rate])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-08 17:47:04.319246: W tensorflow/core/common_runtime/bfc_allocator.cc:479] Allocator (GPU_0_bfc) ran out of memory trying to allocate 9.00MiB (rounded to 9437184)requested by op StatelessRandomUniformV2\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2022-12-08 17:47:04.319320: I tensorflow/core/common_runtime/bfc_allocator.cc:1033] BFCAllocator dump for GPU_0_bfc\n",
      "2022-12-08 17:47:04.319351: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (256): \tTotal Chunks: 25, Chunks in use: 25. 6.2KiB allocated for chunks. 6.2KiB in use in bin. 193B client-requested in use in bin.\n",
      "2022-12-08 17:47:04.319372: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (512): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-12-08 17:47:04.319394: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (1024): \tTotal Chunks: 1, Chunks in use: 1. 1.2KiB allocated for chunks. 1.2KiB in use in bin. 1.0KiB client-requested in use in bin.\n",
      "2022-12-08 17:47:04.319416: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (2048): \tTotal Chunks: 10, Chunks in use: 10. 30.0KiB allocated for chunks. 30.0KiB in use in bin. 30.0KiB client-requested in use in bin.\n",
      "2022-12-08 17:47:04.319434: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (4096): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-12-08 17:47:04.319451: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (8192): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-12-08 17:47:04.319467: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (16384): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-12-08 17:47:04.319484: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (32768): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-12-08 17:47:04.319500: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (65536): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-12-08 17:47:04.319521: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (131072): \tTotal Chunks: 1, Chunks in use: 1. 150.0KiB allocated for chunks. 150.0KiB in use in bin. 150.0KiB client-requested in use in bin.\n",
      "2022-12-08 17:47:04.319541: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (262144): \tTotal Chunks: 1, Chunks in use: 0. 274.2KiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-12-08 17:47:04.319559: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (524288): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-12-08 17:47:04.319575: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (1048576): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-12-08 17:47:04.319595: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (2097152): \tTotal Chunks: 4, Chunks in use: 4. 9.00MiB allocated for chunks. 9.00MiB in use in bin. 9.00MiB client-requested in use in bin.\n",
      "2022-12-08 17:47:04.319615: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (4194304): \tTotal Chunks: 2, Chunks in use: 0. 8.55MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-12-08 17:47:04.319636: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (8388608): \tTotal Chunks: 1, Chunks in use: 1. 10.87MiB allocated for chunks. 10.87MiB in use in bin. 9.00MiB client-requested in use in bin.\n",
      "2022-12-08 17:47:04.319654: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (16777216): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-12-08 17:47:04.319670: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (33554432): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-12-08 17:47:04.319687: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (67108864): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-12-08 17:47:04.319709: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (134217728): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-12-08 17:47:04.319726: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (268435456): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-12-08 17:47:04.319747: I tensorflow/core/common_runtime/bfc_allocator.cc:1056] Bin for 9.00MiB was 8.00MiB, Chunk State: \n",
      "2022-12-08 17:47:04.319762: I tensorflow/core/common_runtime/bfc_allocator.cc:1069] Next region of size 30277632\n",
      "2022-12-08 17:47:04.319788: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f0ada000000 of size 1280 next 1\n",
      "2022-12-08 17:47:04.319804: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f0ada000500 of size 256 next 2\n",
      "2022-12-08 17:47:04.319819: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f0ada000600 of size 256 next 3\n",
      "2022-12-08 17:47:04.319833: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f0ada000700 of size 256 next 4\n",
      "2022-12-08 17:47:04.319847: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f0ada000800 of size 256 next 5\n",
      "2022-12-08 17:47:04.319861: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f0ada000900 of size 256 next 6\n",
      "2022-12-08 17:47:04.319875: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f0ada000a00 of size 256 next 7\n",
      "2022-12-08 17:47:04.319889: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f0ada000b00 of size 256 next 8\n",
      "2022-12-08 17:47:04.319904: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f0ada000c00 of size 256 next 9\n",
      "2022-12-08 17:47:04.319918: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f0ada000d00 of size 256 next 10\n",
      "2022-12-08 17:47:04.319931: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f0ada000e00 of size 256 next 11\n",
      "2022-12-08 17:47:04.319946: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f0ada000f00 of size 256 next 12\n",
      "2022-12-08 17:47:04.319959: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f0ada001000 of size 256 next 13\n",
      "2022-12-08 17:47:04.319973: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f0ada001100 of size 256 next 14\n",
      "2022-12-08 17:47:04.319987: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f0ada001200 of size 256 next 15\n",
      "2022-12-08 17:47:04.320001: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f0ada001300 of size 256 next 16\n",
      "2022-12-08 17:47:04.320015: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f0ada001400 of size 256 next 18\n",
      "2022-12-08 17:47:04.320029: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f0ada001500 of size 3072 next 19\n",
      "2022-12-08 17:47:04.320045: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f0ada002100 of size 3072 next 17\n",
      "2022-12-08 17:47:04.320059: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f0ada002d00 of size 256 next 20\n",
      "2022-12-08 17:47:04.320073: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f0ada002e00 of size 256 next 22\n",
      "2022-12-08 17:47:04.320087: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f0ada002f00 of size 256 next 23\n",
      "2022-12-08 17:47:04.320101: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f0ada003000 of size 3072 next 26\n",
      "2022-12-08 17:47:04.320114: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f0ada003c00 of size 3072 next 27\n",
      "2022-12-08 17:47:04.320128: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f0ada004800 of size 256 next 28\n",
      "2022-12-08 17:47:04.320142: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f0ada004900 of size 256 next 29\n",
      "2022-12-08 17:47:04.320158: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f0ada004a00 of size 3072 next 32\n",
      "2022-12-08 17:47:04.320173: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f0ada005600 of size 3072 next 35\n",
      "2022-12-08 17:47:04.320187: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f0ada006200 of size 3072 next 37\n",
      "2022-12-08 17:47:04.320200: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f0ada006e00 of size 3072 next 39\n",
      "2022-12-08 17:47:04.320214: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f0ada007a00 of size 3072 next 30\n",
      "2022-12-08 17:47:04.320228: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f0ada008600 of size 3072 next 31\n",
      "2022-12-08 17:47:04.320242: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f0ada009200 of size 256 next 41\n",
      "2022-12-08 17:47:04.320256: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f0ada009300 of size 256 next 42\n",
      "2022-12-08 17:47:04.320270: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f0ada009400 of size 256 next 43\n",
      "2022-12-08 17:47:04.320300: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f0ada009500 of size 256 next 44\n",
      "2022-12-08 17:47:04.320318: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] Free  at 7f0ada009600 of size 280832 next 24\n",
      "2022-12-08 17:47:04.320332: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f0ada04df00 of size 153600 next 25\n",
      "2022-12-08 17:47:04.320347: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] Free  at 7f0ada073700 of size 4718592 next 34\n",
      "2022-12-08 17:47:04.320361: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f0ada4f3700 of size 2359296 next 33\n",
      "2022-12-08 17:47:04.320376: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f0ada733700 of size 2359296 next 36\n",
      "2022-12-08 17:47:04.320390: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f0ada973700 of size 2359296 next 38\n",
      "2022-12-08 17:47:04.320405: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f0adabb3700 of size 2359296 next 40\n",
      "2022-12-08 17:47:04.320419: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] Free  at 7f0adadf3700 of size 4251648 next 21\n",
      "2022-12-08 17:47:04.320434: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f0adb201700 of size 11397376 next 18446744073709551615\n",
      "2022-12-08 17:47:04.320450: I tensorflow/core/common_runtime/bfc_allocator.cc:1094]      Summary of in-use Chunks by size: \n",
      "2022-12-08 17:47:04.320469: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 25 Chunks of size 256 totalling 6.2KiB\n",
      "2022-12-08 17:47:04.320487: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 1 Chunks of size 1280 totalling 1.2KiB\n",
      "2022-12-08 17:47:04.320507: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 10 Chunks of size 3072 totalling 30.0KiB\n",
      "2022-12-08 17:47:04.320526: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 1 Chunks of size 153600 totalling 150.0KiB\n",
      "2022-12-08 17:47:04.320542: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 4 Chunks of size 2359296 totalling 9.00MiB\n",
      "2022-12-08 17:47:04.320559: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 1 Chunks of size 11397376 totalling 10.87MiB\n",
      "2022-12-08 17:47:04.320579: I tensorflow/core/common_runtime/bfc_allocator.cc:1101] Sum Total of in-use chunks: 20.05MiB\n",
      "2022-12-08 17:47:04.320595: I tensorflow/core/common_runtime/bfc_allocator.cc:1103] total_region_allocated_bytes_: 30277632 memory_limit_: 30277632 available bytes: 0 curr_region_allocation_bytes_: 60555264\n",
      "2022-12-08 17:47:04.320620: I tensorflow/core/common_runtime/bfc_allocator.cc:1109] Stats: \n",
      "Limit:                        30277632\n",
      "InUse:                        21026560\n",
      "MaxInUse:                     30277376\n",
      "NumAllocs:                          83\n",
      "MaxAllocSize:                 11397376\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2022-12-08 17:47:04.320648: W tensorflow/core/common_runtime/bfc_allocator.cc:491] **_______________********************************_____________********************************xxxxxx\n",
      "2022-12-08 17:47:04.320699: W tensorflow/core/framework/op_kernel.cc:1780] OP_REQUIRES failed at stateless_random_ops_v2.cc:67 : RESOURCE_EXHAUSTED: OOM when allocating tensor with shape[768,3072] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n",
      "/home/alex/.local/lib/python3.10/site-packages/keras/initializers/initializers_v2.py:120: UserWarning: The initializer GlorotUniform is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  warnings.warn(\n",
      "2022-12-08 17:47:14.332586: W tensorflow/core/common_runtime/bfc_allocator.cc:479] Allocator (GPU_0_bfc) ran out of memory trying to allocate 9.00MiB (rounded to 9437184)requested by op StatelessRandomUniformV2\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2022-12-08 17:47:14.332659: I tensorflow/core/common_runtime/bfc_allocator.cc:1033] BFCAllocator dump for GPU_0_bfc\n",
      "2022-12-08 17:47:14.332690: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (256): \tTotal Chunks: 25, Chunks in use: 25. 6.2KiB allocated for chunks. 6.2KiB in use in bin. 193B client-requested in use in bin.\n",
      "2022-12-08 17:47:14.332713: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (512): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-12-08 17:47:14.332734: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (1024): \tTotal Chunks: 1, Chunks in use: 1. 1.2KiB allocated for chunks. 1.2KiB in use in bin. 1.0KiB client-requested in use in bin.\n",
      "2022-12-08 17:47:14.332756: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (2048): \tTotal Chunks: 10, Chunks in use: 10. 30.0KiB allocated for chunks. 30.0KiB in use in bin. 30.0KiB client-requested in use in bin.\n",
      "2022-12-08 17:47:14.332774: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (4096): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-12-08 17:47:14.332792: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (8192): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-12-08 17:47:14.332808: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (16384): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-12-08 17:47:14.332825: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (32768): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-12-08 17:47:14.332842: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (65536): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-12-08 17:47:14.332864: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (131072): \tTotal Chunks: 1, Chunks in use: 1. 150.0KiB allocated for chunks. 150.0KiB in use in bin. 150.0KiB client-requested in use in bin.\n",
      "2022-12-08 17:47:14.332884: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (262144): \tTotal Chunks: 1, Chunks in use: 0. 274.2KiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-12-08 17:47:14.332902: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (524288): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-12-08 17:47:14.332919: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (1048576): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-12-08 17:47:14.332939: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (2097152): \tTotal Chunks: 4, Chunks in use: 4. 9.00MiB allocated for chunks. 9.00MiB in use in bin. 9.00MiB client-requested in use in bin.\n",
      "2022-12-08 17:47:14.332958: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (4194304): \tTotal Chunks: 2, Chunks in use: 0. 8.55MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-12-08 17:47:14.332980: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (8388608): \tTotal Chunks: 1, Chunks in use: 1. 10.87MiB allocated for chunks. 10.87MiB in use in bin. 9.00MiB client-requested in use in bin.\n",
      "2022-12-08 17:47:14.332998: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (16777216): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-12-08 17:47:14.333015: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (33554432): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-12-08 17:47:14.333032: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (67108864): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-12-08 17:47:14.333056: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (134217728): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-12-08 17:47:14.333074: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (268435456): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-12-08 17:47:14.333095: I tensorflow/core/common_runtime/bfc_allocator.cc:1056] Bin for 9.00MiB was 8.00MiB, Chunk State: \n",
      "2022-12-08 17:47:14.333111: I tensorflow/core/common_runtime/bfc_allocator.cc:1069] Next region of size 30277632\n",
      "2022-12-08 17:47:14.333137: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f0ada000000 of size 1280 next 1\n",
      "2022-12-08 17:47:14.333154: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f0ada000500 of size 256 next 2\n",
      "2022-12-08 17:47:14.333169: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f0ada000600 of size 256 next 3\n",
      "2022-12-08 17:47:14.333184: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f0ada000700 of size 256 next 4\n",
      "2022-12-08 17:47:14.333198: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f0ada000800 of size 256 next 5\n",
      "2022-12-08 17:47:14.333212: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f0ada000900 of size 256 next 6\n",
      "2022-12-08 17:47:14.333226: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f0ada000a00 of size 256 next 7\n",
      "2022-12-08 17:47:14.333241: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f0ada000b00 of size 256 next 8\n",
      "2022-12-08 17:47:14.333255: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f0ada000c00 of size 256 next 9\n",
      "2022-12-08 17:47:14.333269: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f0ada000d00 of size 256 next 10\n",
      "2022-12-08 17:47:14.333284: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f0ada000e00 of size 256 next 11\n",
      "2022-12-08 17:47:14.333298: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f0ada000f00 of size 256 next 12\n",
      "2022-12-08 17:47:14.333312: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f0ada001000 of size 256 next 13\n",
      "2022-12-08 17:47:14.333326: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f0ada001100 of size 256 next 14\n",
      "2022-12-08 17:47:14.333341: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f0ada001200 of size 256 next 15\n",
      "2022-12-08 17:47:14.333355: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f0ada001300 of size 256 next 16\n",
      "2022-12-08 17:47:14.333369: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f0ada001400 of size 256 next 18\n",
      "2022-12-08 17:47:14.333384: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f0ada001500 of size 3072 next 19\n",
      "2022-12-08 17:47:14.333401: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f0ada002100 of size 3072 next 17\n",
      "2022-12-08 17:47:14.333416: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f0ada002d00 of size 256 next 20\n",
      "2022-12-08 17:47:14.333431: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f0ada002e00 of size 256 next 22\n",
      "2022-12-08 17:47:14.333445: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f0ada002f00 of size 256 next 23\n",
      "2022-12-08 17:47:14.333460: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f0ada003000 of size 3072 next 26\n",
      "2022-12-08 17:47:14.333475: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f0ada003c00 of size 3072 next 27\n",
      "2022-12-08 17:47:14.333489: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f0ada004800 of size 256 next 28\n",
      "2022-12-08 17:47:14.333504: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f0ada004900 of size 256 next 29\n",
      "2022-12-08 17:47:14.333519: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f0ada004a00 of size 3072 next 32\n",
      "2022-12-08 17:47:14.333537: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f0ada005600 of size 3072 next 35\n",
      "2022-12-08 17:47:14.333554: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f0ada006200 of size 3072 next 37\n",
      "2022-12-08 17:47:14.333569: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f0ada006e00 of size 3072 next 39\n",
      "2022-12-08 17:47:14.333584: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f0ada007a00 of size 3072 next 30\n",
      "2022-12-08 17:47:14.333599: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f0ada008600 of size 3072 next 31\n",
      "2022-12-08 17:47:14.333614: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f0ada009200 of size 256 next 41\n",
      "2022-12-08 17:47:14.333629: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f0ada009300 of size 256 next 42\n",
      "2022-12-08 17:47:14.333644: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f0ada009400 of size 256 next 43\n",
      "2022-12-08 17:47:14.333669: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f0ada009500 of size 256 next 44\n",
      "2022-12-08 17:47:14.333685: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] Free  at 7f0ada009600 of size 280832 next 24\n",
      "2022-12-08 17:47:14.333701: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f0ada04df00 of size 153600 next 25\n",
      "2022-12-08 17:47:14.333717: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] Free  at 7f0ada073700 of size 4718592 next 34\n",
      "2022-12-08 17:47:14.333735: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f0ada4f3700 of size 2359296 next 33\n",
      "2022-12-08 17:47:14.333750: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f0ada733700 of size 2359296 next 36\n",
      "2022-12-08 17:47:14.333765: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f0ada973700 of size 2359296 next 38\n",
      "2022-12-08 17:47:14.333781: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f0adabb3700 of size 2359296 next 40\n",
      "2022-12-08 17:47:14.333798: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] Free  at 7f0adadf3700 of size 4251648 next 21\n",
      "2022-12-08 17:47:14.333814: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f0adb201700 of size 11397376 next 18446744073709551615\n",
      "2022-12-08 17:47:14.333829: I tensorflow/core/common_runtime/bfc_allocator.cc:1094]      Summary of in-use Chunks by size: \n",
      "2022-12-08 17:47:14.333849: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 25 Chunks of size 256 totalling 6.2KiB\n",
      "2022-12-08 17:47:14.333867: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 1 Chunks of size 1280 totalling 1.2KiB\n",
      "2022-12-08 17:47:14.333886: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 10 Chunks of size 3072 totalling 30.0KiB\n",
      "2022-12-08 17:47:14.333907: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 1 Chunks of size 153600 totalling 150.0KiB\n",
      "2022-12-08 17:47:14.333924: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 4 Chunks of size 2359296 totalling 9.00MiB\n",
      "2022-12-08 17:47:14.333942: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 1 Chunks of size 11397376 totalling 10.87MiB\n",
      "2022-12-08 17:47:14.333960: I tensorflow/core/common_runtime/bfc_allocator.cc:1101] Sum Total of in-use chunks: 20.05MiB\n",
      "2022-12-08 17:47:14.333976: I tensorflow/core/common_runtime/bfc_allocator.cc:1103] total_region_allocated_bytes_: 30277632 memory_limit_: 30277632 available bytes: 0 curr_region_allocation_bytes_: 60555264\n",
      "2022-12-08 17:47:14.334009: I tensorflow/core/common_runtime/bfc_allocator.cc:1109] Stats: \n",
      "Limit:                        30277632\n",
      "InUse:                        21026560\n",
      "MaxInUse:                     30277376\n",
      "NumAllocs:                          85\n",
      "MaxAllocSize:                 11397376\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2022-12-08 17:47:14.334038: W tensorflow/core/common_runtime/bfc_allocator.cc:491] **_______________********************************_____________********************************xxxxxx\n",
      "2022-12-08 17:47:14.334086: W tensorflow/core/framework/op_kernel.cc:1780] OP_REQUIRES failed at stateless_random_ops_v2.cc:67 : RESOURCE_EXHAUSTED: OOM when allocating tensor with shape[768,3072] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Exception encountered when calling layer \"MlpBlock_3\" \"                 f\"(type Sequential).\n\n{{function_node __wrapped__StatelessRandomUniformV2_device_/job:localhost/replica:0/task:0/device:GPU:0}} OOM when allocating tensor with shape[768,3072] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:StatelessRandomUniformV2]\n\nCall arguments received by layer \"MlpBlock_3\" \"                 f\"(type Sequential):\n  • inputs=tf.Tensor(shape=(None, 50, 768), dtype=float32)\n  • training=False\n  • mask=None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m/home/alex/Documents/AI_proj/repo/shroom/model_notebook.ipynb Cell 14\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/alex/Documents/AI_proj/repo/shroom/model_notebook.ipynb#X16sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Calling the evaulate method directly on a Tensorflow Dataset works just fine\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/alex/Documents/AI_proj/repo/shroom/model_notebook.ipynb#X16sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m dum_model \u001b[39m=\u001b[39m load_model(\u001b[39m\"\u001b[39;49m\u001b[39m/home/alex/Documents/AI_proj/repo/shroom/client/saved_model/prime.h5\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/alex/Documents/AI_proj/repo/shroom/model_notebook.ipynb#X16sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m test_result_1 \u001b[39m=\u001b[39m dum_model\u001b[39m.\u001b[39mevaluate(test_set)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/vit_keras/layers.py:173\u001b[0m, in \u001b[0;36mTransformerBlock.call\u001b[0;34m(self, inputs, training)\u001b[0m\n\u001b[1;32m    171\u001b[0m x \u001b[39m=\u001b[39m x \u001b[39m+\u001b[39m inputs\n\u001b[1;32m    172\u001b[0m y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayernorm2(x)\n\u001b[0;32m--> 173\u001b[0m y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmlpblock(y)\n\u001b[1;32m    174\u001b[0m \u001b[39mreturn\u001b[39;00m x \u001b[39m+\u001b[39m y, weights\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: Exception encountered when calling layer \"MlpBlock_3\" \"                 f\"(type Sequential).\n\n{{function_node __wrapped__StatelessRandomUniformV2_device_/job:localhost/replica:0/task:0/device:GPU:0}} OOM when allocating tensor with shape[768,3072] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:StatelessRandomUniformV2]\n\nCall arguments received by layer \"MlpBlock_3\" \"                 f\"(type Sequential):\n  • inputs=tf.Tensor(shape=(None, 50, 768), dtype=float32)\n  • training=False\n  • mask=None"
     ]
    }
   ],
   "source": [
    "# Calling the evaulate method directly on a Tensorflow Dataset works just fine\n",
    "test_result_1 = model.evaluate(test_set)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, layer in enumerate(base_model.layers):\n",
    "#    print(i, layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving our model for re-use in the saved_model folder. NOTE: For Niklas, you can use model.load() on the saved model to use it in a method call in the backend\n",
    "model.save(\"prime.h5\")\n",
    "\n",
    "run[\"metrics/test_accuracy\"].log(test_result_1)\n",
    "#run[\"metrics/test_accuracy_fine\"].log(test_result_2)\n",
    "run[\"my_model/saved_model\"].upload(\"prime.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://app.neptune.ai/alnor/DIT825/m/DIT-MOD/v/DIT-MOD-4\n",
      "Remember to stop your model_version once you’ve finished logging your metadata (https://docs.neptune.ai/api/model_version#stop). It will be stopped automatically only when the notebook kernel/interactive console is terminated.\n"
     ]
    }
   ],
   "source": [
    "version_2 = neptune.init_model_version(\n",
    "    model=\"DIT-MOD\",\n",
    "    project=\"alnor/DIT825\"\n",
    ")\n",
    "\n",
    "version_2[\"model\"].upload(\"prime.h5\")\n",
    "version_2[\"validation/acc\"] = 0.806925\n",
    "version_2[\"testing/acc\"] = 0.806925\n",
    "version_2[\"training/acc\"] = 0.999549\n",
    "\n",
    "version_2.change_stage(\"production\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shutting down background jobs, please wait a moment...\n",
      "Done!\n",
      "Waiting for the remaining 74 operations to synchronize with Neptune. Do not kill this process.\n",
      "All 74 operations synced, thanks for waiting!\n",
      "Explore the metadata in the Neptune app:\n",
      "https://app.neptune.ai/alnor/DIT825/e/DIT-89\n"
     ]
    }
   ],
   "source": [
    "run.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "init_model = load_model(\n",
    "    '/home/alex/Documents/AI_proj/repo/shroom/client/saved_model/prime.h5'\n",
    "    )\n",
    "\n",
    "#init_model.predict(\"/home/alex/Documents/AI_proj/repo/shroom/client/media/001_jNbj1WMvR-8_e02fmlw.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 34ms/step\n",
      "[[9.8777525e-07 6.3555981e-06 7.3536000e-08 7.5086587e-07 8.5984766e-08\n",
      "  1.7105616e-08 4.2874934e-08 1.1997899e-08 6.2936720e-06 1.9339440e-08\n",
      "  9.9998534e-01 2.6667998e-08]]\n"
     ]
    }
   ],
   "source": [
    "path = \"/home/alex/Documents/AI_proj/repo/shroom/001_jNbj1WMvR-8.jpg\"\n",
    "\n",
    "img = utils.load_img(\n",
    "    path,\n",
    "    color_mode='rgb',\n",
    "    target_size=(224, 224)\n",
    ")\n",
    "\n",
    "input_arr = utils.img_to_array(img)\n",
    "\n",
    "input_arr = np.array([input_arr])\n",
    "\n",
    "pred = init_model.predict(input_arr)\n",
    "\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-12 13:16:17.949635: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8600\n",
      "2022-12-12 13:16:18.822961: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209/209 [==============================] - 67s 253ms/step - loss: 0.0058 - accuracy: 0.9994 - val_loss: 0.7145 - val_accuracy: 0.8384\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'History' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/alex/Documents/AI_proj/repo/shroom/model_notebook.ipynb Cell 21\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/alex/Documents/AI_proj/repo/shroom/model_notebook.ipynb#X26sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m history \u001b[39m=\u001b[39m init_model\u001b[39m.\u001b[39mfit(training_set, validation_data\u001b[39m=\u001b[39mvalidation_set, epochs\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/alex/Documents/AI_proj/repo/shroom/model_notebook.ipynb#X26sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m loss \u001b[39m=\u001b[39m history[\u001b[39m'\u001b[39;49m\u001b[39mloss\u001b[39;49m\u001b[39m'\u001b[39;49m]\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/alex/Documents/AI_proj/repo/shroom/model_notebook.ipynb#X26sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mprint\u001b[39m(loss)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'History' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "history = init_model.fit(training_set, validation_data=validation_set, epochs=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loss', 'accuracy']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.005834301467984915]\n",
      "[0.9993997812271118]\n"
     ]
    }
   ],
   "source": [
    "loss = history.history['loss']\n",
    "acc = history.history['accuracy']\n",
    "\n",
    "print(loss)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
